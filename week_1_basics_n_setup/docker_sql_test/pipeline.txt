docker run -it \
    -e POSTGRES_USER="felipe123" \
    -e POSTGRES_PASSWORD="felipe123" \
    -e POSTGRES_DB="ny_taxi_test" \
    -v $(pwd)/teste2:/var/lib/postgresql/data \
    -p 5432:5432 \
    postgres:13

pgcli -h localhost -p 5432 -u felipe123 -d ny_taxi_test


## pgadmin

docker run -it \
  -e PGADMIN_DEFAULT_EMAIL="admin@admin.com" \
  -e PGADMIN_DEFAULT_PASSWORD="root" \
  -p 8080:80 \
  dpage/pgadmin4

Após isso precisamos criar um servidor, porém se colocarmos localhost
nesse servidor ele estará tentando achar o postgres nesse container de cima.
Desta forma precisamos conectar ao outro container com imagem do postgres
e criar uma conexão entre dois containers.

## network

docker network create pg-network


docker run -it \
    -e POSTGRES_USER="felipe123" \
    -e POSTGRES_PASSWORD="felipe123" \
    -e POSTGRES_DB="ny_taxi" \
    -v $(pwd)/ny_taxi_postgres:/var/lib/postgresql/data \
    -p 5432:5432 \
    --network=pg-network \
    --name pg-database \
    postgres:13

(pg-database é a forma como o pgadmin vai achar o postgres)

docker run -it \
  -e PGADMIN_DEFAULT_EMAIL="admin@admin.com" \
  -e PGADMIN_DEFAULT_PASSWORD="root" \
  -p 8080:80 \
  --network=pg-network \
  --name pg-admin \
  dpage/pgadmin4

Entrar no site http://localhost:8080/browser/ e criar um servidor
lembrar que o nome do hostname deve ser o nome do docker postgres (pg-database)
username e password de acordo com o docker


https://www.nyc.gov/assets/tlc/downloads/pdf/data_dictionary_trip_records_yellow.pdf
https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-01.parquet



Ao invés de rodar vários terminais para cada container, vamos achar um modo de
colocar tudo em um só. Antes disso, vamos achar um modo de criar um pipeline
que puxa os dados, cria engine e um database, além de alimentar o mesmo.

Uma forma de fazer com que o jupyter notebook vire um arquivo.py automaticamente
é rodando jupyter nbconvert --to=script nome.do.arquivo.ipynb

Vamos criar o arquivo igest_data.py, que é para criar o database

Após isso deve-se criar o dockerfile com a imagem para rodar o ingest_data.py

Dockefile:

FROM python:latest
RUN apt-get install wget
RUN pip install pandas sqlalchemy pyarrow psycopg2
COPY ingest_data.py ingest_data.py
ENTRYPOINT [ "python","ingest_data.py" ]

docker build -t sql_taxi:02 .

docker run -it \
  --network="host" \
  sql_taxi:04 \
   felipe123 \  user
   felipe123 \  password
   localhost \  localhost
   5432 \       porta
   ny_taxi \    db_name from postgres docker
   yellow_taxi_driver_2021  name of the database on pgadmin

Motivo de usar --network="host"
https://stackoverflow.com/questions/24319662/from-inside-of-a-docker-container-how-do-i-connect-to-the-localhost-of-the-mach/24326540#24326540


docker-compose

Ao fazer docker-compose não é necessário criar uma network para conectá-los.
Para criar um docker-compose:

services:
  name:
    imagename:
    enviroments:
    volumes:
    ports:
  name2:
    imagename:
    enviroments:
    volumes:
    ports:


Nesse caso seria:

docker-compose up (-d para detached mode, ou seja, usa o terminal enquanto roda)

services:
  pgdatabase (nome do usuário durante o registro):
    image: postgres:13
    environment:
      - POSTGRES_USER=felipe123
      - POSTGRES_PASSWORD=felipe123
      - POSTGRES_DB=ny_taxi
    volumes:
      - "./ny_taxi_postgres:/var/lib/postgresql/data:rw"
    ports:
      - "5432:5432"
  pgadmin:
    image: dpage/pgadmin4
    environment:
      - PGADMIN_DEFAULT_EMAIL=admin@admin.com
      - PGADMIN_DEFAULT_PASSWORD=root
    ports: [8080:80]

"docker-compose down" para desligar o docker-compose
O nome do network criado, que não é mostrado durante a criação ou citada durante o running do
docker-compose, é *nome.do.arquivo*_default

Caso queira manter os dados de conexão, deve-se fazer um volume (missão achar como fazer isso)

Entretanto, caso você rode o docker-compose up -d acima, perceberá que não vai haver nenhuma tabela nele.
Para isso é preciso rodar o docker do ingest_data.py criado com algumas mudanças:

docker run -it \
  --network=docker_sql_test_default \ (nesse caso é o nome do network criado pelo docker composer que é descrito acima)
  sql_taxi:04 \
   felipe123 \
   felipe123 \
   pgdatabase \ (AQUI O NOME DO DOCKER SERVICE TAMBÉM É O HOST )
   5432 \
   ny_taxi \
   yellow_taxi_driver_2021

Criar infraestrutura para data lake e data warehouse
Para isso precisamos ir no projeto criado no GCP e dar permissões como de "Administrador de Storage" e "Admnistrador de Objetos"
Um para o Backet e outro para objetos no backets
Além disso precisamos da permissão de "Big Query".

Precisams tambem habilitar as API, o cloud do local environment e o cloud não se comunicam diratemente
mas sim por APIs.

Para usar o Teraform precisamos de 3 files pelo menos: main.tf, variables.tf e .terraform-version

Para melhor entendimento do terraform, visitar os seguintes links:
https://github.com/ziritrion/dataeng-zoomcamp/blob/main/notes/1_intro.md#gcp-initial-setup
https://developer.hashicorp.com/terraform/tutorials/gcp-get-started
https://www.youtube.com/watch?v=tE1WZg9ib8k&ab_channel=PagarmeTalks
